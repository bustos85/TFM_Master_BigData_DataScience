{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso de textblob para hacer el an√°lisis de sentimiento de los tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports y configuraciones necesarias\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# !pip install textblob (en caso de no tenerlo instalado previamente)\n",
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "conf = (SparkSession\\\n",
    "          .builder\\\n",
    "          .appName(\"twitter\")\\\n",
    "          .master(\"spark://MacBook-Pro-de-Jose.local:7077\")\\\n",
    "          .config(\"spark.io.compression.codec\", \"snappy\")\\\n",
    "          .getOrCreate())  \n",
    "\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uso del conector Spark y MongoDB\n",
    "\n",
    "Cogemos los datos cargados en MongoDB, tanto en ingl√©s como en espa√±ol, almacenados desde el inicio del flujo con Apache Nifi.\n",
    "\n",
    "Usaremos estos datos para testear el uso de textblob para obtener el sentimiento de los textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mongo_english = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "    .option(\"spark.mongodb.input.uri\", \"mongodb://localhost:27017/tfm_twitter.tweets_english\").load()\n",
    "\n",
    "df_mongo_spanish = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "    .option(\"spark.mongodb.input.uri\", \"mongodb://localhost:27017/tfm_twitter.tweets_spanish\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nos quedamos en ambos dataframes con la columna texto que es la que nos interesa\n",
    "df_text_english = df_mongo_english[['text']]\n",
    "df_text_spanish = df_mongo_spanish[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas_spanish = df_text_spanish.toPandas()\n",
    "df_pandas_english = df_text_english.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df spanish: num_rows: 79036\tColumnas: 1\n",
      "\n",
      "Df english: num_rows: 322364\tColumnas: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Df spanish: num_rows: %d\\tColumnas: %d\\n\" % (df_pandas_spanish.shape[0], df_pandas_spanish.shape[1]) )\n",
    "print(\"Df english: num_rows: %d\\tColumnas: %d\\n\" % (df_pandas_english.shape[0], df_pandas_english.shape[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@EJFC26 Y Messi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @btsmoonchild64: These group photos deserve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@rehankkhanNDS Overacting *</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pay day play dayü§ëü§ëü§ëü§ëü§ë</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@pandaeyed1 Thank you!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @liamyoung: Strange that Tony Blair has sud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hard work puts you where good luck can find you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @xCiphxr: When creative kids try playing co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @bonang_m: I‚Äôm working on one as we speak. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RT @akashbanerjee: After #PulwamaAttack, terro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                    @EJFC26 Y Messi\n",
       "1  RT @btsmoonchild64: These group photos deserve...\n",
       "2                        @rehankkhanNDS Overacting *\n",
       "3                              Pay day play dayü§ëü§ëü§ëü§ëü§ë\n",
       "4                             @pandaeyed1 Thank you!\n",
       "5  RT @liamyoung: Strange that Tony Blair has sud...\n",
       "6   Hard work puts you where good luck can find you.\n",
       "7  RT @xCiphxr: When creative kids try playing co...\n",
       "8  RT @bonang_m: I‚Äôm working on one as we speak. ...\n",
       "9  RT @akashbanerjee: After #PulwamaAttack, terro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas_english.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer la prueba con textblob calculando el sentimiento de cada tweet con los tweets en ingl√©s, ya que la librer√≠a no funciona igual con otros idiomas, y habr√≠a que traducir los textos primero, lo cual es un proceso bastante costoso computacionalmente y reduce despu√©s la efectividad de la librer√≠a al obtener el sentimiento de un texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpieza de los textos.\n",
    "\n",
    "Vamos a aplicar a todos los textos del dataframe, t√©cnicas de preprocesado y limpieza de textos para hacer m√°s efectivos y sencillos los an√°lisis de los textos y la clasificaci√≥n del sentimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones de preprocesado y limpieza de los textos\n",
    "def limpiar_tweet(tweet):\n",
    "    # quitamos RT, @nombre_usuario, links y urls, hashtags, menciones, caracteres extra√±os o emoticonos\n",
    "    tweet = re.sub('  +', ' ', tweet)\n",
    "    # eliminar acentos\n",
    "    tweet = ''.join((c for c in unicodedata.normalize('NFD', tweet) if unicodedata.category(c) != 'Mn'))  \n",
    "    # convertir la repetici√≥n de una letra m√°s de 2 veces a 1\n",
    "    # biennnnn --> bien\n",
    "    tweet = re.sub(r'(.)\\1+', r'\\1\\1', tweet)\n",
    "    # eliminar \"RT\", \"@usuario\", o los enlaces que es informaci√≥n que no ser√≠a √∫til analizar\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub('','',tweet).lower() \n",
    "    tweet = re.sub(r'http\\S+', '', tweet) \n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    tweet = re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet)\n",
    "    tweet = re.sub(r'[0-9]', '', tweet) \n",
    " \n",
    "    return tweet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicamos las funciones a los textos del dataframe, primero hacemos una copia para conservar el original\n",
    "df_clean_english = df_pandas_english.copy()\n",
    "df_clean_english['text'] = df_clean_english['text'].apply(limpiar_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Df english:\n",
      "                                                      text\n",
      "322354  im so excited to see the talents of united com...\n",
      "322355     dianne abbott in charge of immigration  the...\n",
      "322356     police are searching for an attacker armed ...\n",
      "322357                                     your dad      \n",
      "322358     conservative party leadership faces a membe...\n",
      "322359              deep purple   highway star  video hq \n",
      "322360                                      this edit tho\n",
      "322361  i am on now one of the  train rides i am takin...\n",
      "322362    the next   years will be spent slowly watchi...\n",
      "322363                            ya allahh toothless    \n"
     ]
    }
   ],
   "source": [
    "# damos un vistazo a los textos resultantes sobre los que aplicaremos textblob\n",
    "print(\"\\nDf english:\\n\", df_clean_english.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicar textblob para obtener el sentimiento de cada texto\n",
    "\n",
    "TextBlob hace un An√°lisis de Sentimiento en cualquier texto dado. La propiedad de sentimiento indica la puntuaci√≥n de sentimiento del texto. Se dan dos puntuaciones: Polaridad y Subjetividad.\n",
    "\n",
    "La puntuaci√≥n de polaridad es un valor dentro del rango [-1.0, 1.0] donde un valor negativo indica un texto negativo, y un valor positivo indica que el texto es positivo.\n",
    "\n",
    "La subjetividad es un valor dentro del rango [0.0, 1.0] donde 0.0 es muy objetivo y 1.0 es muy subjetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones para aplicar textblob al conjunto de textos, y obtener para cada texto el valor de la polaridad.\n",
    "# Para valores positivos asignamos el valor '2', para valores igual a 0 que ser√≠an textos con sentimiento neutro\n",
    "# asignamos un '1', y por √∫ltimo para valores negativos asignamos el valor '0'.\n",
    "def analizar_sentimiento(tweet):\n",
    "    analysis = TextBlob(tweet)\n",
    "        \n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 2\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicar textblob a textos en ingl√©s. Lo calculamos sobre los datos originales y los preprocesados.\n",
    "df_pandas_english['sentiment'] = df_pandas_english['text'].apply(analizar_sentimiento)\n",
    "df_clean_english['sentiment'] = df_clean_english['text'].apply(analizar_sentimiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales en ingl√©s: \n",
      "                                                 text  sentiment\n",
      "0                                    @EJFC26 Y Messi          1\n",
      "1  RT @btsmoonchild64: These group photos deserve...          2\n",
      "2                        @rehankkhanNDS Overacting *          1\n",
      "3                              Pay day play dayü§ëü§ëü§ëü§ëü§ë          1\n",
      "4                             @pandaeyed1 Thank you!          1\n",
      "5  RT @liamyoung: Strange that Tony Blair has sud...          0\n",
      "6   Hard work puts you where good luck can find you.          2\n",
      "7  RT @xCiphxr: When creative kids try playing co...          2\n",
      "8  RT @bonang_m: I‚Äôm working on one as we speak. ...          2\n",
      "9  RT @akashbanerjee: After #PulwamaAttack, terro...          2\n",
      "\n",
      "\n",
      "Datos preprocesados en ingl√©s: \n",
      "                                                 text  sentiment\n",
      "0                                            y messi          1\n",
      "1         these group photos deserve more attention           2\n",
      "2                                       overacting            1\n",
      "3                                 pay day play day            1\n",
      "4                                         thank you           1\n",
      "5     strange that tony blair has suddenly become...          0\n",
      "6   hard work puts you where good luck can find you           2\n",
      "7               when creative kids try playing comp           2\n",
      "8    m  i m working on one as we speak  thank you...          2\n",
      "9     after pulwamaattack  terrorists scored a bi...          2\n"
     ]
    }
   ],
   "source": [
    "print(\"Datos originales en ingl√©s: \\n\", df_pandas_english.head(10))\n",
    "print('\\n')\n",
    "print(\"Datos preprocesados en ingl√©s: \\n\", df_clean_english.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para visualizarlo cambiamos el valor num√©rico por positivo, neutral y negativo\n",
    "def get_tweet_sentiment(sentiment): \n",
    "    if sentiment > 1: \n",
    "        return 'Positivo'\n",
    "    elif sentiment == 1: \n",
    "        return 'Neutral'\n",
    "    else: \n",
    "        return 'Negativo'\n",
    "\n",
    "df_pandas_english['sentiment'] = df_pandas_english['sentiment'].apply(get_tweet_sentiment)\n",
    "df_clean_english['sentiment'] = df_clean_english['sentiment'].apply(get_tweet_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuento valores datos originales en ingl√©s: Neutral     144212\n",
      "Positivo    122267\n",
      "Negativo     55885\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n",
      "Recuento valores datos procesados en ingl√©s: Neutral     142972\n",
      "Positivo    124522\n",
      "Negativo     54870\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ver resultados obtenidos\n",
    "# vemos los distintos valores que tiene la columna del sentimiento en ambos datasets\n",
    "print(\"Recuento valores datos originales en ingl√©s:\",pd.value_counts(df_pandas_english['sentiment']))\n",
    "print('\\n')\n",
    "print(\"Recuento valores datos procesados en ingl√©s:\",pd.value_counts(df_clean_english['sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comentarios sobre los resultados\n",
    "\n",
    "No se aprecian apenas cambios entre usar textblob con los tweets tal cual se almacenan y recogen, que despu√©s de haberlos preprocesado para limpiarlos de caracteres extra√±os o informaci√≥n que no sea √∫til para el an√°lisis de sentimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargamos los csv generados con tweets anotados tanto en ingl√©s como espa√±ol.\n",
    "\n",
    "Estos datos ya con sentimiento calculado para cada texto, podremos usarlos para entrenar y testear alg√∫n modelo que viene con la librer√≠a textblob para clasificar textos, y tambi√©n si les quitamos los datos del sentimiento para testear el % de acierto de textblob, pas√°ndolos por la librer√≠a y luego comparando con el original anotado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_rows: 1759315\tColumnas: 2\n",
      "\n",
      "Columnas:\n",
      " ['text', 'sentiment']\n"
     ]
    }
   ],
   "source": [
    "# Los datos de sentimiento vienen con los valores: positivo=2, neutral=1, negativo=0\n",
    "# cargamos datos en ingl√©s\n",
    "df_anotados_english = pd.read_csv('./data/df_result_english.csv', sep=',')\n",
    "\n",
    "print(\"num_rows: %d\\tColumnas: %d\\n\" % (df_anotados_english.shape[0], df_anotados_english.shape[1]) )\n",
    "print(\"Columnas:\\n\", list(df_anotados_english.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                @VirginAmerica What @dhepburn said.        1.0\n",
       "1  @VirginAmerica plus you've added commercials t...        2.0\n",
       "2  @VirginAmerica I didn't today... Must mean I n...        1.0\n",
       "3  @VirginAmerica it's really aggressive to blast...        0.0\n",
       "4  @VirginAmerica and it's a really big bad thing...        0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anotados_english.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha cargado los datos de sentimiento como float, posiblemente porque alg√∫n valor viene como NaN o similar, sustituimos esos valores por -1 y luego eliminamos esos registros antes de convertir la columna en int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anotados_english = df_anotados_english.fillna(-1)\n",
    "df_anotados_english = df_anotados_english[df_anotados_english['sentiment']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_float = df_anotados_english.columns[df_anotados_english.dtypes == float]\n",
    "df_anotados_english[c_float] = df_anotados_english[c_float].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                @VirginAmerica What @dhepburn said.          1\n",
       "1  @VirginAmerica plus you've added commercials t...          2\n",
       "2  @VirginAmerica I didn't today... Must mean I n...          1\n",
       "3  @VirginAmerica it's really aggressive to blast...          0\n",
       "4  @VirginAmerica and it's a really big bad thing...          0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anotados_english.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_rows: 48658\tColumnas: 2\n",
      "\n",
      "Columnas:\n",
      " ['text', 'sentiment']\n"
     ]
    }
   ],
   "source": [
    "# cargamos datos en espa√±ol\n",
    "df_anotados_spanish = pd.read_csv('./data/df_result_spanish.csv', sep=',')\n",
    "\n",
    "print(\"num_rows: %d\\tColumnas: %d\\n\" % (df_anotados_spanish.shape[0], df_anotados_spanish.shape[1]) )\n",
    "print(\"Columnas:\\n\", list(df_anotados_spanish.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@PauladeLasHeras No te libraras de ayudar me/n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@marodriguezb Gracias MAR</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Off pensando en el regalito Sinde, la que se v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conozco a alguien q es adicto al drama! Ja ja ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toca @crackoviadeTV3 . Grabaci√≥n dl especial N...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Buen d√≠a todos! Lo primero mandar un abrazo gr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Desde el esca√±o. Todo listo para empezar #endi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bd√≠as. EM no se ira de puente. Si vosotros os ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Un sistema econ√≥mico q recorta dinero para pre...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#programascambiados caca d ajuste</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  @PauladeLasHeras No te libraras de ayudar me/n...          1\n",
       "1                          @marodriguezb Gracias MAR          2\n",
       "2  Off pensando en el regalito Sinde, la que se v...          0\n",
       "3  Conozco a alguien q es adicto al drama! Ja ja ...          2\n",
       "4  Toca @crackoviadeTV3 . Grabaci√≥n dl especial N...          2\n",
       "5  Buen d√≠a todos! Lo primero mandar un abrazo gr...          2\n",
       "6  Desde el esca√±o. Todo listo para empezar #endi...          2\n",
       "7  Bd√≠as. EM no se ira de puente. Si vosotros os ...          2\n",
       "8  Un sistema econ√≥mico q recorta dinero para pre...          2\n",
       "9                  #programascambiados caca d ajuste          0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anotados_spanish.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos otro dataframe con los textos en ingles, quitando del original el sentimiento, para aplicarle textblob\n",
    "df_noAnotados_english = df_anotados_english[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicamos al dataframe de textos no anotados la funci√≥n de limpieza de textos\n",
    "df_clean_noAnotados = df_noAnotados_english.copy()\n",
    "df_clean_noAnotados['text'] = df_clean_noAnotados['text'].apply(limpiar_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what   said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus you ve added commercials to the experie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i didn t today   must mean i need to take an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it s really aggressive to blast obnoxious  e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and it s a really big bad thing about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seriously would pay   a flight for seats tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes  nearly every time i fly vx this  ear wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>really missed a prime opportunity for men wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>well  i didn t but now i do    d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it was amazing  and arrived an hour early  y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                       what   said \n",
       "1    plus you ve added commercials to the experie...\n",
       "2    i didn t today   must mean i need to take an...\n",
       "3    it s really aggressive to blast obnoxious  e...\n",
       "4           and it s a really big bad thing about it\n",
       "5    seriously would pay   a flight for seats tha...\n",
       "6    yes  nearly every time i fly vx this  ear wo...\n",
       "7    really missed a prime opportunity for men wi...\n",
       "8                   well  i didn t but now i do    d\n",
       "9    it was amazing  and arrived an hour early  y..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_noAnotados.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what   said</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus you ve added commercials to the experie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i didn t today   must mean i need to take an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it s really aggressive to blast obnoxious  e...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and it s a really big bad thing about it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seriously would pay   a flight for seats tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes  nearly every time i fly vx this  ear wo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>really missed a prime opportunity for men wi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>well  i didn t but now i do    d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it was amazing  and arrived an hour early  y...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                                       what   said           1\n",
       "1    plus you ve added commercials to the experie...          1\n",
       "2    i didn t today   must mean i need to take an...          0\n",
       "3    it s really aggressive to blast obnoxious  e...          2\n",
       "4           and it s a really big bad thing about it          0\n",
       "5    seriously would pay   a flight for seats tha...          0\n",
       "6    yes  nearly every time i fly vx this  ear wo...          2\n",
       "7    really missed a prime opportunity for men wi...          2\n",
       "8                   well  i didn t but now i do    d          1\n",
       "9    it was amazing  and arrived an hour early  y...          2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aplicar textblob para ver el sentimiento que arroja para cada texto\n",
    "df_clean_noAnotados['sentiment'] = df_clean_noAnotados['text'].apply(analizar_sentimiento)\n",
    "df_clean_noAnotados.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuento valores datos originales en ingl√©s anotados: 2    872864\n",
      "0    871980\n",
      "1     14470\n",
      "Name: sentiment, dtype: int64\n",
      "Recuento valores datos pasados por textblob: 2    777433\n",
      "1    614305\n",
      "0    367576\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# vemos el recuento de valores 0, 1 y 2 tanto para los datos anotados originales, como los anotados por textblob\n",
    "print(\"Recuento valores datos originales en ingl√©s anotados:\",pd.value_counts(df_anotados_english['sentiment']))\n",
    "print(\"Recuento valores datos pasados por textblob:\",pd.value_counts(df_clean_noAnotados['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales en ingl√©s anotados: \n",
      "                                                 text  sentiment\n",
      "0                @VirginAmerica What @dhepburn said.          1\n",
      "1  @VirginAmerica plus you've added commercials t...          2\n",
      "2  @VirginAmerica I didn't today... Must mean I n...          1\n",
      "3  @VirginAmerica it's really aggressive to blast...          0\n",
      "4  @VirginAmerica and it's a really big bad thing...          0\n",
      "5  @VirginAmerica seriously would pay $30 a fligh...          0\n",
      "6  @VirginAmerica yes, nearly every time I fly VX...          2\n",
      "7  @VirginAmerica Really missed a prime opportuni...          1\n",
      "8    @virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D          2\n",
      "9  @VirginAmerica it was amazing, and arrived an ...          2\n",
      "\n",
      "\n",
      "Datos preprocesados en ingl√©s y anotados mediante textblob: \n",
      "                                                 text  sentiment\n",
      "0                                       what   said           1\n",
      "1    plus you ve added commercials to the experie...          1\n",
      "2    i didn t today   must mean i need to take an...          0\n",
      "3    it s really aggressive to blast obnoxious  e...          2\n",
      "4           and it s a really big bad thing about it          0\n",
      "5    seriously would pay   a flight for seats tha...          0\n",
      "6    yes  nearly every time i fly vx this  ear wo...          2\n",
      "7    really missed a prime opportunity for men wi...          2\n",
      "8                   well  i didn t but now i do    d          1\n",
      "9    it was amazing  and arrived an hour early  y...          2\n"
     ]
    }
   ],
   "source": [
    "print(\"Datos originales en ingl√©s anotados: \\n\", df_anotados_english.head(10))\n",
    "print('\\n')\n",
    "print(\"Datos preprocesados en ingl√©s y anotados mediante textblob: \\n\", df_clean_noAnotados.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introducimos en una copia del dataframe original anotado la columna del sentimiento calculado por textblob \n",
    "# para despu√©s comparar los valores y ver el n√∫mero de registros donde textblob no ha calculado el mismo \n",
    "# valor de sentimiento.\n",
    "df_anotados_copia = df_anotados_english.copy()\n",
    "df_anotados_copia['sentiment_textblob'] = df_clean_noAnotados['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  \\\n",
       "0                @VirginAmerica What @dhepburn said.          1   \n",
       "1  @VirginAmerica plus you've added commercials t...          2   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...          1   \n",
       "3  @VirginAmerica it's really aggressive to blast...          0   \n",
       "4  @VirginAmerica and it's a really big bad thing...          0   \n",
       "5  @VirginAmerica seriously would pay $30 a fligh...          0   \n",
       "6  @VirginAmerica yes, nearly every time I fly VX...          2   \n",
       "7  @VirginAmerica Really missed a prime opportuni...          1   \n",
       "8    @virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D          2   \n",
       "9  @VirginAmerica it was amazing, and arrived an ...          2   \n",
       "\n",
       "   sentiment_textblob  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   0  \n",
       "3                   2  \n",
       "4                   0  \n",
       "5                   0  \n",
       "6                   2  \n",
       "7                   2  \n",
       "8                   1  \n",
       "9                   2  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anotados_copia.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "diferencias = df_anotados_copia[df_anotados_copia['sentiment'] != df_anotados_copia['sentiment_textblob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero filas datos originales: 1759314\n",
      "\n",
      "N√∫mero de valores diferentes: 975540\n",
      "\n",
      "Porcentaje de registros mal clasificados: 55.450022\n"
     ]
    }
   ],
   "source": [
    "print(\"N√∫mero filas datos originales: %d\\n\" % (df_anotados_english.shape[0]) )\n",
    "print(\"N√∫mero de valores diferentes: %d\\n\" % (diferencias.shape[0]) )\n",
    "print(\"Porcentaje de registros mal clasificados: %f\" % ((diferencias.shape[0]/df_anotados_english.shape[0])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar como hay bastante diferencia en el sentimiento de los datos que vienen ya con el valor del sentimiento anotado (partimos de la suposici√≥n de que estos datos est√°n correctamente etiquetados), y el sentimiento de los datos que anotamos su sentimiento mediante el uso de textblob.\n",
    "\n",
    "Con los datos que tenemos anotados, textblob habr√≠a etiquetado err√≥neamente un 55,45%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uso de clasificador de textblob\n",
    "\n",
    "Por √∫ltimo vamos a usar un algoritmo de clasificaci√≥n que trae textblob (Naive Bayes), entren√°ndolo con los datos anotados tanto en ingl√©s, como en espa√±ol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  sentiment\n",
      "0                @VirginAmerica What @dhepburn said.          1\n",
      "1  @VirginAmerica plus you've added commercials t...          2\n",
      "2  @VirginAmerica I didn't today... Must mean I n...          1\n",
      "3  @VirginAmerica it's really aggressive to blast...          0\n",
      "4  @VirginAmerica and it's a really big bad thing...          0\n",
      "5  @VirginAmerica seriously would pay $30 a fligh...          0\n",
      "6  @VirginAmerica yes, nearly every time I fly VX...          2\n",
      "7  @VirginAmerica Really missed a prime opportuni...          1\n",
      "8    @virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D          2\n",
      "9  @VirginAmerica it was amazing, and arrived an ...          2\n",
      "\n",
      "\n",
      "                                                text  sentiment\n",
      "0  @PauladeLasHeras No te libraras de ayudar me/n...          1\n",
      "1                          @marodriguezb Gracias MAR          2\n",
      "2  Off pensando en el regalito Sinde, la que se v...          0\n",
      "3  Conozco a alguien q es adicto al drama! Ja ja ...          2\n",
      "4  Toca @crackoviadeTV3 . Grabaci√≥n dl especial N...          2\n",
      "5  Buen d√≠a todos! Lo primero mandar un abrazo gr...          2\n",
      "6  Desde el esca√±o. Todo listo para empezar #endi...          2\n",
      "7  Bd√≠as. EM no se ira de puente. Si vosotros os ...          2\n",
      "8  Un sistema econ√≥mico q recorta dinero para pre...          2\n",
      "9                  #programascambiados caca d ajuste          0\n"
     ]
    }
   ],
   "source": [
    "# tenemos los dataframes cargados en ingl√©s y espa√±ol ya anotados con su sentimiento\n",
    "print(df_anotados_english.head(10))\n",
    "print(\"\\n\")\n",
    "print(df_anotados_spanish.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cogemos un sample de ambos dataframes, para evitar el alto coste computacional de usar tantos datos\n",
    "df_sample_english = df_anotados_english.sample(frac=0.01, replace=False, random_state=1)\n",
    "df_sample_spanish = df_anotados_spanish.sample(frac=0.3, replace=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos los conjuntos de train y test para entrenar y evaluar el modelo\n",
    "# convertimos los datos en lista, y repartimos 70% train y 30% test\n",
    "data_english = df_sample_english[['text', 'sentiment']].values.tolist()\n",
    "train_index = int(0.70 * len(data_english))\n",
    "train_english, test_english = data_english[:train_index], data_english[train_index: ]\n",
    "\n",
    "data_spanish = df_sample_spanish[['text', 'sentiment']].values.tolist()\n",
    "train_index = int(0.70 * len(data_spanish))\n",
    "train_spanish, test_spanish = data_spanish[:train_index], data_spanish[train_index: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ingl√©s: 12315 \t Test ingl√©s: 5278\n",
      "Train espa√±ol: 10217 \t Test espa√±ol: 4380\n"
     ]
    }
   ],
   "source": [
    "print(\"Train ingl√©s: %d \\t Test ingl√©s: %d\" % (len(train_english), len(test_english)))\n",
    "print(\"Train espa√±ol: %d \\t Test espa√±ol: %d\" % (len(train_spanish), len(test_spanish)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos el clasificador para ingl√©s\n",
    "classifier_english = NaiveBayesClassifier(train_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7254641909814323\n"
     ]
    }
   ],
   "source": [
    "# calcular accuracy del clasificador con tweets en ingl√©s\n",
    "accuracy_english = classifier_english.accuracy(test_english)\n",
    "print (accuracy_english) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos el clasificador para espa√±ol\n",
    "classifier_spanish = NaiveBayesClassifier(train_spanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819634703196347\n"
     ]
    }
   ],
   "source": [
    "# calcular accuracy del clasificador con tweets en espa√±ol\n",
    "accuracy_spanish = classifier_spanish.accuracy(test_spanish)\n",
    "print (accuracy_spanish) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "            contains(RT) = True                1 : 0      =    157.2 : 1.0\n",
      "     contains(Microsoft) = True                1 : 2      =    120.6 : 1.0\n",
      "        contains(Street) = True                1 : 0      =    112.3 : 1.0\n",
      "       contains(JetBlue) = True                1 : 2      =    111.7 : 1.0\n",
      "     contains(microsoft) = True                1 : 2      =    111.7 : 1.0\n",
      "            contains(Ur) = True                1 : 0      =     67.4 : 1.0\n",
      "        contains(client) = True                1 : 0      =     67.4 : 1.0\n",
      "     contains(lightning) = True                1 : 0      =     67.4 : 1.0\n",
      "         contains(Bones) = True                1 : 0      =     67.4 : 1.0\n",
      "         contains(Robin) = True                1 : 0      =     67.4 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# vemos las features m√°s informativas/importantes en ingl√©s\n",
    "print (classifier_english.show_informative_features(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "        contains(riesgo) = True                1 : 2      =     55.8 : 1.0\n",
      "          contains(cont) = True                2 : 0      =     44.3 : 1.0\n",
      "        contains(Buenas) = True                2 : 0      =     36.7 : 1.0\n",
      "            contains(FF) = True                2 : 0      =     30.8 : 1.0\n",
      "          contains(peor) = True                0 : 2      =     29.5 : 1.0\n",
      "      contains(denuncia) = True                0 : 2      =     27.7 : 1.0\n",
      " contains(AlejandroSanz) = True                2 : 0      =     27.5 : 1.0\n",
      "         contains(feliz) = True                2 : 0      =     27.2 : 1.0\n",
      "   contains(interesante) = True                1 : 0      =     27.1 : 1.0\n",
      "       contains(d√©ficit) = True                0 : 2      =     26.7 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# vemos las features m√°s informativas/importantes en espa√±ol\n",
    "print (classifier_spanish.show_informative_features(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a ver si con los textos preprocesados se mejora la precisi√≥n del clasificador\n",
    "# aplicamos las funciones de limpieza a los textos, primero hacemos una copia para conservar el original\n",
    "df_clean_english = df_anotados_english.copy()\n",
    "df_clean_english['text'] = df_clean_english['text'].apply(limpiar_tweet)\n",
    "\n",
    "df_clean_spanish = df_anotados_spanish.copy()\n",
    "df_clean_spanish['text'] = df_clean_spanish['text'].apply(limpiar_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divisi√≥n de los datos preprocesados en train y test \n",
    "df_sample_english_2 = df_clean_english.sample(frac=0.01, replace=False, random_state=1)\n",
    "df_sample_spanish_2 = df_clean_spanish.sample(frac=0.3, replace=False, random_state=1)\n",
    "\n",
    "data_english_2 = df_sample_english_2[['text', 'sentiment']].values.tolist()\n",
    "train_index = int(0.70 * len(data_english_2))\n",
    "train_english_2, test_english_2 = data_english_2[:train_index], data_english_2[train_index: ]\n",
    "\n",
    "data_spanish_2 = df_sample_spanish_2[['text', 'sentiment']].values.tolist()\n",
    "train_index = int(0.70 * len(data_spanish_2))\n",
    "train_spanish_2, test_spanish_2 = data_spanish_2[:train_index], data_spanish_2[train_index: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7283061765820387\n"
     ]
    }
   ],
   "source": [
    "# clasificador de textos en ingl√©s\n",
    "classifier_english_2 = NaiveBayesClassifier(train_english_2)\n",
    "\n",
    "accuracy_english_2 = classifier_english_2.accuracy(test_english_2)\n",
    "print (accuracy_english_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.813013698630137\n"
     ]
    }
   ],
   "source": [
    "# clasificador de textos en espa√±ol\n",
    "classifier_spanish_2 = NaiveBayesClassifier(train_spanish_2)\n",
    "\n",
    "accuracy_spanish_2 = classifier_spanish_2.accuracy(test_spanish_2)\n",
    "print (accuracy_spanish_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones del uso de textblob\n",
    "\n",
    "Lo comentado anteriormente, aplicando Textblob sobre tweets sin etiquetar se acierta un % razonable, pero vemos un % de error al etiquetar el sentimiento bastante elevado. Adem√°s el uso con los tweets en espa√±ol est√° desaconsejado por temas de coste computacional al tener que traducir los textos, y una posible p√©rdida de eficiencia si la traducci√≥n no es exacta.\n",
    "\n",
    "Uno de los problemas de textblob es que no consigue del todo acertar con el contexto y subjetividad de los textos, y se ve bastante afectado en sus resultados por ello. Aunque esto es obviamente el gran problema de cualquier t√©cnica de clasificaci√≥n de textos.\n",
    "\n",
    "Al usar un clasificador que viene con textblob como Naive Bayes, y entrenarlo con tweets ya anotados, tanto en ingl√©s como en espa√±ol se ven unos mejores resultados, aunque suponemos que al no poder entrenar con mayor cantidad de datos debido a limitaciones de c√≥mputo e infraestructura no se obtienen los mejores resultados posibles. Tambi√©n recalcar que se vuelve a probar con el clasificador tanto con los datos originales como con los datos preprocesados tras limpiarlos, y se obtienen unos resultados muy similares.\n",
    "\n",
    "De todos modos la m√©dida para evaluar los modelos usada, la precisi√≥n, no es la m√°s adecuada, y cuando probemos con otros modelos y algoritmos de clasificaci√≥n usaremos otras m√©tricas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
