{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso de textblob para hacer el anÃ¡lisis de sentimiento de los tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports y configuraciones necesarias\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# !pip install textblob (en caso de no tenerlo instalado previamente)\n",
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "conf = (SparkSession\\\n",
    "          .builder\\\n",
    "          .appName(\"twitter\")\\\n",
    "          .master(\"spark://MacBook-Pro-de-Jose.local:7077\")\\\n",
    "          .config(\"spark.io.compression.codec\", \"snappy\")\\\n",
    "          .getOrCreate())  \n",
    "\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uso del conector Spark y MongoDB\n",
    "\n",
    "Cogemos los datos cargados en MongoDB, tanto en inglÃ©s como en espaÃ±ol, almacenados desde el inicio del flujo con Apache Nifi.\n",
    "\n",
    "Usaremos estos datos para testear el uso de textblob para obtener el sentimiento de los textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mongo_english = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "    .option(\"spark.mongodb.input.uri\", \"mongodb://localhost:27017/tfm_twitter.tweets_english\").load()\n",
    "\n",
    "df_mongo_spanish = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "    .option(\"spark.mongodb.input.uri\", \"mongodb://localhost:27017/tfm_twitter.tweets_spanish\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nos quedamos en ambos dataframes con la columna texto que es la que nos interesa\n",
    "df_text_english = df_mongo_english[['text']]\n",
    "df_text_spanish = df_mongo_spanish[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas_spanish = df_text_spanish.toPandas()\n",
    "df_pandas_english = df_text_english.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df spanish: num_rows: 79036\tColumnas: 1\n",
      "\n",
      "Df english: num_rows: 322364\tColumnas: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Df spanish: num_rows: %d\\tColumnas: %d\\n\" % (df_pandas_spanish.shape[0], df_pandas_spanish.shape[1]) )\n",
    "print(\"Df english: num_rows: %d\\tColumnas: %d\\n\" % (df_pandas_english.shape[0], df_pandas_english.shape[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@EJFC26 Y Messi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @btsmoonchild64: These group photos deserve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@rehankkhanNDS Overacting *</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pay day play dayðŸ¤‘ðŸ¤‘ðŸ¤‘ðŸ¤‘ðŸ¤‘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@pandaeyed1 Thank you!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @liamyoung: Strange that Tony Blair has sud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hard work puts you where good luck can find you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @xCiphxr: When creative kids try playing co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @bonang_m: Iâ€™m working on one as we speak. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RT @akashbanerjee: After #PulwamaAttack, terro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                    @EJFC26 Y Messi\n",
       "1  RT @btsmoonchild64: These group photos deserve...\n",
       "2                        @rehankkhanNDS Overacting *\n",
       "3                              Pay day play dayðŸ¤‘ðŸ¤‘ðŸ¤‘ðŸ¤‘ðŸ¤‘\n",
       "4                             @pandaeyed1 Thank you!\n",
       "5  RT @liamyoung: Strange that Tony Blair has sud...\n",
       "6   Hard work puts you where good luck can find you.\n",
       "7  RT @xCiphxr: When creative kids try playing co...\n",
       "8  RT @bonang_m: Iâ€™m working on one as we speak. ...\n",
       "9  RT @akashbanerjee: After #PulwamaAttack, terro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas_english.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer la prueba con textblob calculando el sentimiento de cada tweet con los tweets en inglÃ©s, ya que la librerÃ­a no funciona igual con otros idiomas, y habrÃ­a que traducir los textos primero, lo cual es un proceso bastante costoso computacionalmente y reduce despuÃ©s la efectividad de la librerÃ­a al obtener el sentimiento de un texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpieza de los textos.\n",
    "\n",
    "Vamos a aplicar a todos los textos del dataframe, tÃ©cnicas de preprocesado y limpieza de textos para hacer mÃ¡s efectivos y sencillos los anÃ¡lisis de los textos y la clasificaciÃ³n del sentimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones de preprocesado y limpieza de los textos\n",
    "def limpiar_tweet(tweet):\n",
    "    # quitamos RT, @nombre_usuario, links y urls, hashtags, menciones, caracteres extraÃ±os o emoticonos\n",
    "    tweet = re.sub('  +', ' ', tweet)\n",
    "    # eliminar acentos\n",
    "    tweet = ''.join((c for c in unicodedata.normalize('NFD', tweet) if unicodedata.category(c) != 'Mn'))  \n",
    "    # convertir la repeticiÃ³n de una letra mÃ¡s de 2 veces a 1\n",
    "    # biennnnn --> bien\n",
    "    tweet = re.sub(r'(.)\\1+', r'\\1\\1', tweet)\n",
    "    # eliminar \"RT\", \"@usuario\", o los enlaces que es informaciÃ³n que no serÃ­a Ãºtil analizar\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub('','',tweet).lower() \n",
    "    tweet = re.sub(r'http\\S+', '', tweet) \n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    tweet = re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet)\n",
    "    tweet = re.sub(r'[0-9]', '', tweet) \n",
    " \n",
    "    return tweet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicamos las funciones a los textos del dataframe, primero hacemos una copia para conservar el original\n",
    "df_clean_english = df_pandas_english.copy()\n",
    "df_clean_english['text'] = df_clean_english['text'].apply(limpiar_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Df english:\n",
      "                                                      text\n",
      "322354  im so excited to see the talents of united com...\n",
      "322355     dianne abbott in charge of immigration  the...\n",
      "322356     police are searching for an attacker armed ...\n",
      "322357                                     your dad      \n",
      "322358     conservative party leadership faces a membe...\n",
      "322359              deep purple   highway star  video hq \n",
      "322360                                      this edit tho\n",
      "322361  i am on now one of the  train rides i am takin...\n",
      "322362    the next   years will be spent slowly watchi...\n",
      "322363                            ya allahh toothless    \n"
     ]
    }
   ],
   "source": [
    "# damos un vistazo a los textos resultantes sobre los que aplicaremos textblob\n",
    "print(\"\\nDf english:\\n\", df_clean_english.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicar textblob para obtener el sentimiento de cada texto\n",
    "\n",
    "TextBlob hace un AnÃ¡lisis de Sentimiento en cualquier texto dado. La propiedad de sentimiento indica la puntuaciÃ³n de sentimiento del texto. Se dan dos puntuaciones: Polaridad y Subjetividad.\n",
    "\n",
    "La puntuaciÃ³n de polaridad es un valor dentro del rango [-1.0, 1.0] donde un valor negativo indica un texto negativo, y un valor positivo indica que el texto es positivo.\n",
    "\n",
    "La subjetividad es un valor dentro del rango [0.0, 1.0] donde 0.0 es muy objetivo y 1.0 es muy subjetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones para aplicar textblob al conjunto de textos, y obtener para cada texto el valor de la polaridad.\n",
    "# Para valores positivos asignamos el valor '2', para valores igual a 0 que serÃ­an textos con sentimiento neutro\n",
    "# asignamos un '1', y por Ãºltimo para valores negativos asignamos el valor '0'.\n",
    "def analizar_sentimiento(tweet):\n",
    "    analysis = TextBlob(tweet)\n",
    "        \n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 2\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicar textblob a textos en inglÃ©s. Lo calculamos sobre los datos originales y los preprocesados.\n",
    "df_pandas_english['sentiment'] = df_pandas_english['text'].apply(analizar_sentimiento)\n",
    "df_clean_english['sentiment'] = df_clean_english['text'].apply(analizar_sentimiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales en inglÃ©s: \n",
      "                                                 text  sentiment\n",
      "0                                    @EJFC26 Y Messi          1\n",
      "1  RT @btsmoonchild64: These group photos deserve...          2\n",
      "2                        @rehankkhanNDS Overacting *          1\n",
      "3                              Pay day play dayðŸ¤‘ðŸ¤‘ðŸ¤‘ðŸ¤‘ðŸ¤‘          1\n",
      "4                             @pandaeyed1 Thank you!          1\n",
      "5  RT @liamyoung: Strange that Tony Blair has sud...          0\n",
      "6   Hard work puts you where good luck can find you.          2\n",
      "7  RT @xCiphxr: When creative kids try playing co...          2\n",
      "8  RT @bonang_m: Iâ€™m working on one as we speak. ...          2\n",
      "9  RT @akashbanerjee: After #PulwamaAttack, terro...          2\n",
      "\n",
      "\n",
      "Datos preprocesados en inglÃ©s: \n",
      "                                                 text  sentiment\n",
      "0                                            y messi          1\n",
      "1         these group photos deserve more attention           2\n",
      "2                                       overacting            1\n",
      "3                                 pay day play day            1\n",
      "4                                         thank you           1\n",
      "5     strange that tony blair has suddenly become...          0\n",
      "6   hard work puts you where good luck can find you           2\n",
      "7               when creative kids try playing comp           2\n",
      "8    m  i m working on one as we speak  thank you...          2\n",
      "9     after pulwamaattack  terrorists scored a bi...          2\n"
     ]
    }
   ],
   "source": [
    "print(\"Datos originales en inglÃ©s: \\n\", df_pandas_english.head(10))\n",
    "print('\\n')\n",
    "print(\"Datos preprocesados en inglÃ©s: \\n\", df_clean_english.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para visualizarlo cambiamos el valor numÃ©rico por positivo, neutral y negativo\n",
    "def get_tweet_sentiment(sentiment): \n",
    "    if sentiment > 1: \n",
    "        return 'Positivo'\n",
    "    elif sentiment == 1: \n",
    "        return 'Neutral'\n",
    "    else: \n",
    "        return 'Negativo'\n",
    "\n",
    "df_pandas_english['sentiment'] = df_pandas_english['sentiment'].apply(get_tweet_sentiment)\n",
    "df_clean_english['sentiment'] = df_clean_english['sentiment'].apply(get_tweet_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuento valores datos originales en inglÃ©s: Neutral     144212\n",
      "Positivo    122267\n",
      "Negativo     55885\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "\n",
      "Recuento valores datos procesados en inglÃ©s: Neutral     142972\n",
      "Positivo    124522\n",
      "Negativo     54870\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ver resultados obtenidos\n",
    "# vemos los distintos valores que tiene la columna del sentimiento en ambos datasets\n",
    "print(\"Recuento valores datos originales en inglÃ©s:\",pd.value_counts(df_pandas_english['sentiment']))\n",
    "print('\\n')\n",
    "print(\"Recuento valores datos procesados en inglÃ©s:\",pd.value_counts(df_clean_english['sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comentarios sobre los resultados\n",
    "\n",
    "No se aprecian apenas cambios entre usar textblob con los tweets tal cual se almacenan y recogen, que despuÃ©s de haberlos preprocesado para limpiarlos de caracteres extraÃ±os o informaciÃ³n que no sea Ãºtil para el anÃ¡lisis de sentimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargamos los csv generados con tweets anotados tanto en inglÃ©s como espaÃ±ol.\n",
    "\n",
    "Estos datos ya con sentimiento calculado para cada texto, podremos usarlos para entrenar y testear algÃºn modelo que viene con la librerÃ­a textblob para clasificar textos, y tambiÃ©n si les quitamos los datos del sentimiento para testear el % de acierto de textblob, pasÃ¡ndolos por la librerÃ­a y luego comparando con el original anotado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_rows: 1759315\tColumnas: 2\n",
      "\n",
      "Columnas:\n",
      " ['text', 'sentiment']\n"
     ]
    }
   ],
   "source": [
    "# Los datos de sentimiento vienen con los valores: positivo=2, neutral=1, negativo=0\n",
    "# cargamos datos en inglÃ©s\n",
    "df_anotados_english = pd.read_csv('./data/df_result_english.csv', sep=',')\n",
    "\n",
    "print(\"num_rows: %d\\tColumnas: %d\\n\" % (df_anotados_english.shape[0], df_anotados_english.shape[1]) )\n",
    "print(\"Columnas:\\n\", list(df_anotados_english.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                @VirginAmerica What @dhepburn said.        1.0\n",
       "1  @VirginAmerica plus you've added commercials t...        2.0\n",
       "2  @VirginAmerica I didn't today... Must mean I n...        1.0\n",
       "3  @VirginAmerica it's really aggressive to blast...        0.0\n",
       "4  @VirginAmerica and it's a really big bad thing...        0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anotados_english.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha cargado los datos de sentimiento como float, posiblemente porque algÃºn valor viene como NaN o similar, sustituimos esos valores por -1 y luego eliminamos esos registros antes de convertir la columna en int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anotados_english = df_anotados_english.fillna(-1)\n",
    "df_anotados_english = df_anotados_english[df_anotados_english['sentiment']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_float = df_anotados_english.columns[df_anotados_english.dtypes == float]\n",
    "df_anotados_english[c_float] = df_anotados_english[c_float].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                @VirginAmerica What @dhepburn said.          1\n",
       "1  @VirginAmerica plus you've added commercials t...          2\n",
       "2  @VirginAmerica I didn't today... Must mean I n...          1\n",
       "3  @VirginAmerica it's really aggressive to blast...          0\n",
       "4  @VirginAmerica and it's a really big bad thing...          0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anotados_english.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_rows: 48658\tColumnas: 2\n",
      "\n",
      "Columnas:\n",
      " ['text', 'sentiment']\n"
     ]
    }
   ],
   "source": [
    "# cargamos datos en espaÃ±ol\n",
    "df_anotados_spanish = pd.read_csv('./data/df_result_spanish.csv', sep=',')\n",
    "\n",
    "print(\"num_rows: %d\\tColumnas: %d\\n\" % (df_anotados_spanish.shape[0], df_anotados_spanish.shape[1]) )\n",
    "print(\"Columnas:\\n\", list(df_anotados_spanish.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@PauladeLasHeras No te libraras de ayudar me/n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@marodriguezb Gracias MAR</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Off pensando en el regalito Sinde, la que se v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conozco a alguien q es adicto al drama! Ja ja ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toca @crackoviadeTV3 . GrabaciÃ³n dl especial N...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Buen dÃ­a todos! Lo primero mandar un abrazo gr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Desde el escaÃ±o. Todo listo para empezar #endi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BdÃ­as. EM no se ira de puente. Si vosotros os ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Un sistema econÃ³mico q recorta dinero para pre...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#programascambiados caca d ajuste</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  @PauladeLasHeras No te libraras de ayudar me/n...          1\n",
       "1                          @marodriguezb Gracias MAR          2\n",
       "2  Off pensando en el regalito Sinde, la que se v...          0\n",
       "3  Conozco a alguien q es adicto al drama! Ja ja ...          2\n",
       "4  Toca @crackoviadeTV3 . GrabaciÃ³n dl especial N...          2\n",
       "5  Buen dÃ­a todos! Lo primero mandar un abrazo gr...          2\n",
       "6  Desde el escaÃ±o. Todo listo para empezar #endi...          2\n",
       "7  BdÃ­as. EM no se ira de puente. Si vosotros os ...          2\n",
       "8  Un sistema econÃ³mico q recorta dinero para pre...          2\n",
       "9                  #programascambiados caca d ajuste          0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anotados_spanish.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos otro dataframe con los textos en ingles, quitando del original el sentimiento, para aplicarle textblob\n",
    "df_noAnotados_english = df_anotados_english[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicamos al dataframe de textos no anotados la funciÃ³n de limpieza de textos\n",
    "df_clean_noAnotados = df_noAnotados_english.copy()\n",
    "df_clean_noAnotados['text'] = df_clean_noAnotados['text'].apply(limpiar_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what   said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus you ve added commercials to the experie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i didn t today   must mean i need to take an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it s really aggressive to blast obnoxious  e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and it s a really big bad thing about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seriously would pay   a flight for seats tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes  nearly every time i fly vx this  ear wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>really missed a prime opportunity for men wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>well  i didn t but now i do    d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it was amazing  and arrived an hour early  y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                       what   said \n",
       "1    plus you ve added commercials to the experie...\n",
       "2    i didn t today   must mean i need to take an...\n",
       "3    it s really aggressive to blast obnoxious  e...\n",
       "4           and it s a really big bad thing about it\n",
       "5    seriously would pay   a flight for seats tha...\n",
       "6    yes  nearly every time i fly vx this  ear wo...\n",
       "7    really missed a prime opportunity for men wi...\n",
       "8                   well  i didn t but now i do    d\n",
       "9    it was amazing  and arrived an hour early  y..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_noAnotados.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what   said</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus you ve added commercials to the experie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i didn t today   must mean i need to take an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it s really aggressive to blast obnoxious  e...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and it s a really big bad thing about it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seriously would pay   a flight for seats tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes  nearly every time i fly vx this  ear wo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>really missed a prime opportunity for men wi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>well  i didn t but now i do    d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it was amazing  and arrived an hour early  y...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                                       what   said           1\n",
       "1    plus you ve added commercials to the experie...          1\n",
       "2    i didn t today   must mean i need to take an...          0\n",
       "3    it s really aggressive to blast obnoxious  e...          2\n",
       "4           and it s a really big bad thing about it          0\n",
       "5    seriously would pay   a flight for seats tha...          0\n",
       "6    yes  nearly every time i fly vx this  ear wo...          2\n",
       "7    really missed a prime opportunity for men wi...          2\n",
       "8                   well  i didn t but now i do    d          1\n",
       "9    it was amazing  and arrived an hour early  y...          2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aplicar textblob para ver el sentimiento que arroja para cada texto\n",
    "df_clean_noAnotados['sentiment'] = df_clean_noAnotados['text'].apply(analizar_sentimiento)\n",
    "df_clean_noAnotados.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuento valores datos originales en inglÃ©s anotados: 2    872864\n",
      "0    871980\n",
      "1     14470\n",
      "Name: sentiment, dtype: int64\n",
      "Recuento valores datos pasados por textblob: 2    777433\n",
      "1    614305\n",
      "0    367576\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# vemos el recuento de valores 0, 1 y 2 tanto para los datos anotados originales, como los anotados por textblob\n",
    "print(\"Recuento valores datos originales en inglÃ©s anotados:\",pd.value_counts(df_anotados_english['sentiment']))\n",
    "print(\"Recuento valores datos pasados por textblob:\",pd.value_counts(df_clean_noAnotados['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales en inglÃ©s anotados: \n",
      "                                                 text  sentiment\n",
      "0                @VirginAmerica What @dhepburn said.          1\n",
      "1  @VirginAmerica plus you've added commercials t...          2\n",
      "2  @VirginAmerica I didn't today... Must mean I n...          1\n",
      "3  @VirginAmerica it's really aggressive to blast...          0\n",
      "4  @VirginAmerica and it's a really big bad thing...          0\n",
      "5  @VirginAmerica seriously would pay $30 a fligh...          0\n",
      "6  @VirginAmerica yes, nearly every time I fly VX...          2\n",
      "7  @VirginAmerica Really missed a prime opportuni...          1\n",
      "8    @virginamerica Well, I didn'tâ€¦but NOW I DO! :-D          2\n",
      "9  @VirginAmerica it was amazing, and arrived an ...          2\n",
      "\n",
      "\n",
      "Datos preprocesados en inglÃ©s y anotados mediante textblob: \n",
      "                                                 text  sentiment\n",
      "0                                       what   said           1\n",
      "1    plus you ve added commercials to the experie...          1\n",
      "2    i didn t today   must mean i need to take an...          0\n",
      "3    it s really aggressive to blast obnoxious  e...          2\n",
      "4           and it s a really big bad thing about it          0\n",
      "5    seriously would pay   a flight for seats tha...          0\n",
      "6    yes  nearly every time i fly vx this  ear wo...          2\n",
      "7    really missed a prime opportunity for men wi...          2\n",
      "8                   well  i didn t but now i do    d          1\n",
      "9    it was amazing  and arrived an hour early  y...          2\n"
     ]
    }
   ],
   "source": [
    "print(\"Datos originales en inglÃ©s anotados: \\n\", df_anotados_english.head(10))\n",
    "print('\\n')\n",
    "print(\"Datos preprocesados en inglÃ©s y anotados mediante textblob: \\n\", df_clean_noAnotados.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introducimos en una copia del dataframe original anotado la columna del sentimiento calculado por textblob \n",
    "# para despuÃ©s comparar los valores y ver el nÃºmero de registros donde textblob no ha calculado el mismo \n",
    "# valor de sentimiento.\n",
    "df_anotados_copia = df_anotados_english.copy()\n",
    "df_anotados_copia['sentiment_textblob'] = df_clean_noAnotados['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@virginamerica Well, I didn'tâ€¦but NOW I DO! :-D</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  \\\n",
       "0                @VirginAmerica What @dhepburn said.          1   \n",
       "1  @VirginAmerica plus you've added commercials t...          2   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...          1   \n",
       "3  @VirginAmerica it's really aggressive to blast...          0   \n",
       "4  @VirginAmerica and it's a really big bad thing...          0   \n",
       "5  @VirginAmerica seriously would pay $30 a fligh...          0   \n",
       "6  @VirginAmerica yes, nearly every time I fly VX...          2   \n",
       "7  @VirginAmerica Really missed a prime opportuni...          1   \n",
       "8    @virginamerica Well, I didn'tâ€¦but NOW I DO! :-D          2   \n",
       "9  @VirginAmerica it was amazing, and arrived an ...          2   \n",
       "\n",
       "   sentiment_textblob  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   0  \n",
       "3                   2  \n",
       "4                   0  \n",
       "5                   0  \n",
       "6                   2  \n",
       "7                   2  \n",
       "8                   1  \n",
       "9                   2  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anotados_copia.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "diferencias = df_anotados_copia[df_anotados_copia['sentiment'] != df_anotados_copia['sentiment_textblob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÃºmero filas datos originales: 1759314\n",
      "\n",
      "NÃºmero de valores diferentes: 975540\n",
      "\n",
      "Porcentaje de registros mal clasificados: 55.450022\n"
     ]
    }
   ],
   "source": [
    "print(\"NÃºmero filas datos originales: %d\\n\" % (df_anotados_english.shape[0]) )\n",
    "print(\"NÃºmero de valores diferentes: %d\\n\" % (diferencias.shape[0]) )\n",
    "print(\"Porcentaje de registros mal clasificados: %f\" % ((diferencias.shape[0]/df_anotados_english.shape[0])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar como hay bastante diferencia en el sentimiento de los datos que vienen ya con el valor del sentimiento anotado (partimos de la suposiciÃ³n de que estos datos estÃ¡n correctamente etiquetados), y el sentimiento de los datos que anotamos su sentimiento mediante el uso de textblob.\n",
    "\n",
    "Con los datos que tenemos anotados, textblob habrÃ­a etiquetado errÃ³neamente un 55,45%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uso de clasificador de textblob\n",
    "\n",
    "Por Ãºltimo vamos a usar un algoritmo de clasificaciÃ³n que trae textblob (Naive Bayes), entrenÃ¡ndolo con los datos anotados tanto en inglÃ©s, como en espaÃ±ol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  sentiment\n",
      "0                @VirginAmerica What @dhepburn said.          1\n",
      "1  @VirginAmerica plus you've added commercials t...          2\n",
      "2  @VirginAmerica I didn't today... Must mean I n...          1\n",
      "3  @VirginAmerica it's really aggressive to blast...          0\n",
      "4  @VirginAmerica and it's a really big bad thing...          0\n",
      "5  @VirginAmerica seriously would pay $30 a fligh...          0\n",
      "6  @VirginAmerica yes, nearly every time I fly VX...          2\n",
      "7  @VirginAmerica Really missed a prime opportuni...          1\n",
      "8    @virginamerica Well, I didn'tâ€¦but NOW I DO! :-D          2\n",
      "9  @VirginAmerica it was amazing, and arrived an ...          2\n",
      "\n",
      "\n",
      "                                                text  sentiment\n",
      "0  @PauladeLasHeras No te libraras de ayudar me/n...          1\n",
      "1                          @marodriguezb Gracias MAR          2\n",
      "2  Off pensando en el regalito Sinde, la que se v...          0\n",
      "3  Conozco a alguien q es adicto al drama! Ja ja ...          2\n",
      "4  Toca @crackoviadeTV3 . GrabaciÃ³n dl especial N...          2\n",
      "5  Buen dÃ­a todos! Lo primero mandar un abrazo gr...          2\n",
      "6  Desde el escaÃ±o. Todo listo para empezar #endi...          2\n",
      "7  BdÃ­as. EM no se ira de puente. Si vosotros os ...          2\n",
      "8  Un sistema econÃ³mico q recorta dinero para pre...          2\n",
      "9                  #programascambiados caca d ajuste          0\n"
     ]
    }
   ],
   "source": [
    "# tenemos los dataframes cargados en inglÃ©s y espaÃ±ol ya anotados con su sentimiento\n",
    "print(df_anotados_english.head(10))\n",
    "print(\"\\n\")\n",
    "print(df_anotados_spanish.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cogemos un sample de ambos dataframes, para evitar el alto coste computacional de usar tantos datos\n",
    "df_sample_english = df_anotados_english.sample(frac=0.01, replace=False, random_state=1)\n",
    "df_sample_spanish = df_anotados_spanish.sample(frac=0.3, replace=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos los conjuntos de train y test para entrenar y evaluar el modelo\n",
    "# convertimos los datos en lista, y repartimos 70% train y 30% test\n",
    "data_english = df_sample_english[['text', 'sentiment']].values.tolist()\n",
    "train_index = int(0.70 * len(data_english))\n",
    "train_english, test_english = data_english[:train_index], data_english[train_index: ]\n",
    "\n",
    "data_spanish = df_sample_spanish[['text', 'sentiment']].values.tolist()\n",
    "train_index = int(0.70 * len(data_spanish))\n",
    "train_spanish, test_spanish = data_spanish[:train_index], data_spanish[train_index: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inglÃ©s: 12315 \t Test inglÃ©s: 5278\n",
      "Train espaÃ±ol: 10217 \t Test espaÃ±ol: 4380\n"
     ]
    }
   ],
   "source": [
    "print(\"Train inglÃ©s: %d \\t Test inglÃ©s: %d\" % (len(train_english), len(test_english)))\n",
    "print(\"Train espaÃ±ol: %d \\t Test espaÃ±ol: %d\" % (len(train_spanish), len(test_spanish)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos el clasificador para inglÃ©s\n",
    "classifier_english = NaiveBayesClassifier(train_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7254641909814323\n"
     ]
    }
   ],
   "source": [
    "# calcular accuracy del clasificador con tweets en inglÃ©s\n",
    "accuracy_english = classifier_english.accuracy(test_english)\n",
    "print (accuracy_english) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos el clasificador para espaÃ±ol\n",
    "classifier_spanish = NaiveBayesClassifier(train_spanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819634703196347\n"
     ]
    }
   ],
   "source": [
    "# calcular accuracy del clasificador con tweets en espaÃ±ol\n",
    "accuracy_spanish = classifier_spanish.accuracy(test_spanish)\n",
    "print (accuracy_spanish) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "            contains(RT) = True                1 : 0      =    157.2 : 1.0\n",
      "     contains(Microsoft) = True                1 : 2      =    120.6 : 1.0\n",
      "        contains(Street) = True                1 : 0      =    112.3 : 1.0\n",
      "       contains(JetBlue) = True                1 : 2      =    111.7 : 1.0\n",
      "     contains(microsoft) = True                1 : 2      =    111.7 : 1.0\n",
      "            contains(Ur) = True                1 : 0      =     67.4 : 1.0\n",
      "        contains(client) = True                1 : 0      =     67.4 : 1.0\n",
      "     contains(lightning) = True                1 : 0      =     67.4 : 1.0\n",
      "         contains(Bones) = True                1 : 0      =     67.4 : 1.0\n",
      "         contains(Robin) = True                1 : 0      =     67.4 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# vemos las features mÃ¡s informativas/importantes en inglÃ©s\n",
    "print (classifier_english.show_informative_features(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "        contains(riesgo) = True                1 : 2      =     55.8 : 1.0\n",
      "          contains(cont) = True                2 : 0      =     44.3 : 1.0\n",
      "        contains(Buenas) = True                2 : 0      =     36.7 : 1.0\n",
      "            contains(FF) = True                2 : 0      =     30.8 : 1.0\n",
      "          contains(peor) = True                0 : 2      =     29.5 : 1.0\n",
      "      contains(denuncia) = True                0 : 2      =     27.7 : 1.0\n",
      " contains(AlejandroSanz) = True                2 : 0      =     27.5 : 1.0\n",
      "         contains(feliz) = True                2 : 0      =     27.2 : 1.0\n",
      "   contains(interesante) = True                1 : 0      =     27.1 : 1.0\n",
      "       contains(dÃ©ficit) = True                0 : 2      =     26.7 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# vemos las features mÃ¡s informativas/importantes en espaÃ±ol\n",
    "print (classifier_spanish.show_informative_features(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a ver si con los textos preprocesados se mejora la precisiÃ³n del clasificador\n",
    "# aplicamos las funciones de limpieza a los textos, primero hacemos una copia para conservar el original\n",
    "df_clean_english = df_anotados_english.copy()\n",
    "df_clean_english['text'] = df_clean_english['text'].apply(limpiar_tweet)\n",
    "\n",
    "df_clean_spanish = df_anotados_spanish.copy()\n",
    "df_clean_spanish['text'] = df_clean_spanish['text'].apply(limpiar_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divisiÃ³n de los datos preprocesados en train y test \n",
    "df_sample_english_2 = df_clean_english.sample(frac=0.01, replace=False, random_state=1)\n",
    "df_sample_spanish_2 = df_clean_spanish.sample(frac=0.3, replace=False, random_state=1)\n",
    "\n",
    "data_english_2 = df_sample_english_2[['text', 'sentiment']].values.tolist()\n",
    "train_index = int(0.70 * len(data_english_2))\n",
    "train_english_2, test_english_2 = data_english_2[:train_index], data_english_2[train_index: ]\n",
    "\n",
    "data_spanish_2 = df_sample_spanish_2[['text', 'sentiment']].values.tolist()\n",
    "train_index = int(0.70 * len(data_spanish_2))\n",
    "train_spanish_2, test_spanish_2 = data_spanish_2[:train_index], data_spanish_2[train_index: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7283061765820387\n"
     ]
    }
   ],
   "source": [
    "# clasificador de textos en inglÃ©s\n",
    "classifier_english_2 = NaiveBayesClassifier(train_english_2)\n",
    "\n",
    "accuracy_english_2 = classifier_english_2.accuracy(test_english_2)\n",
    "print (accuracy_english_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.813013698630137\n"
     ]
    }
   ],
   "source": [
    "# clasificador de textos en espaÃ±ol\n",
    "classifier_spanish_2 = NaiveBayesClassifier(train_spanish_2)\n",
    "\n",
    "accuracy_spanish_2 = classifier_spanish_2.accuracy(test_spanish_2)\n",
    "print (accuracy_spanish_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones del uso de textblob\n",
    "\n",
    "Lo comentado anteriormente, aplicando Textblob sobre tweets sin etiquetar se acierta un % razonable, pero vemos un % de error al etiquetar el sentimiento bastante elevado. AdemÃ¡s el uso con los tweets en espaÃ±ol estÃ¡ desaconsejado por temas de coste computacional al tener que traducir los textos, y una posible pÃ©rdida de eficiencia si la traducciÃ³n no es exacta.\n",
    "\n",
    "Uno de los problemas de textblob es que no consigue del todo acertar con el contexto y subjetividad de los textos, y se ve bastante afectado en sus resultados por ello. Aunque esto es obviamente el gran problema de cualquier tÃ©cnica de clasificaciÃ³n de textos.\n",
    "\n",
    "Al usar un clasificador que viene con textblob como Naive Bayes, y entrenarlo con tweets ya anotados, tanto en inglÃ©s como en espaÃ±ol se ven unos mejores resultados, aunque suponemos que al no poder entrenar con mayor cantidad de datos debido a limitaciones de cÃ³mputo e infraestructura no se obtienen los mejores resultados posibles. TambiÃ©n recalcar que se vuelve a probar con el clasificador tanto con los datos originales como con los datos preprocesados tras limpiarlos, y se obtienen unos resultados muy similares.\n",
    "\n",
    "De todos modos la mÃ©dida para evaluar los modelos usada, la precisiÃ³n, no es la mÃ¡s adecuada, y cuando probemos con otros modelos y algoritmos de clasificaciÃ³n usaremos otras mÃ©tricas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
